{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import itertools\n",
    "import multiprocessing as mp\n",
    "from datetime import date, timedelta\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import norm\n",
    "import randomforestanalysis as RFA\n",
    "from matplotlib import rc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define data source and file path to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# available data sources are CCCSL, WHOPHSM and CORONANET\n",
    "datasource = \"CCCSL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapt as necessary\n",
    "\n",
    "if datasource == \"CCCSL\":\n",
    "    datapath = '../data/COVID19_data_cumulative_PAPER_VERSION.csv'\n",
    "    file_ending = ''\n",
    "\n",
    "else:\n",
    "    file_ending = '_'+datasource\n",
    "    datapath = '../data/other_sources/COVID19_data_cumulative_PAPER_VERSION'+file_ending+'.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise random forest analysis object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rfa = RFA.RandomForestAnalysis(timeshift=[s for s in range(0,21)],\n",
    "                               n_splits=10,\n",
    "                               enddate = date(2020,4,30),\n",
    "                               minsamples_leaf=[1],\n",
    "                               max_tree_depth = [d for d in range(1,16)],\n",
    "                               max_features = [k/100 for k in range(1,101)],\n",
    "                               n_estimators=500,\n",
    "                               outcome_name = \"R\",\n",
    "                               data_path = datapath\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfa._measurenames = list(rfa.data.columns[10:-5],)\n",
    "rfa.get_predictors()\n",
    "rfa.get_outcome()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crossvalidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rfa.crossvalidate(n_processes=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Determine best value for hyperparameter m, depending on time shift s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfa.get_performance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot heatmap of hyperparameter dependent model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,15))\n",
    "ax = plt.gca()\n",
    "cax = plt.imshow(rfa.performance.loc[(10,1,slice(None),slice(None)),[(\"R2_test\",\"mean\")]].droplevel(['timeshift','min_samples_leaf']).unstack(level=1).values[:10,:],aspect=10,vmin=0.40,vmax=0.475)\n",
    "cbar = fig.colorbar(cax, orientation='vertical',shrink=.825,label=\"$<r^2>$\")\n",
    "cbar.ax.set_yticklabels([\"$\\leq$ 0.4\",\"0.41\",\"0.42\",\"0.43\",\"0.44\",\"0.45\",\"0.46\",\"0.47\"])\n",
    "plt.xticks([19,39,59,79,99],[20,40,60,80,100])\n",
    "plt.yticks(np.arange(1,11,2),np.arange(2,11,2))\n",
    "ax.set_ylabel('Maximum tree depth $d$')\n",
    "ax.set_xlabel('Percentage $m$ of features considered')\n",
    "plt.savefig('crossvalidation_RF_heatmap'+file_ending+'.pdf',bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get list of countries in each continent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = pd.read_csv('countries.csv',header=0,sep=';',index_col=\"Country\",usecols=[\"Country\",\"Europe+Africa\",\"Asia+Oceania\",\"Americas\"]).fillna(False).replace(1,True)\n",
    "\n",
    "countrylists = dict()\n",
    "\n",
    "countrylists[\"Americas\"] = list(countries.loc[countries[\"Americas\"]==True].index)\n",
    "countrylists[\"Asia\"]     = list(countries.loc[countries[\"Asia+Oceania\"]==True].index)\n",
    "countrylists[\"Europe\"]   = list(countries.loc[countries[\"Europe+Africa\"]==True].index)\n",
    "countrylists[\"None\"]     = []\n",
    "\n",
    "permutation_importances = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute permutation importances for main analysis and continent knockout experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = rfa._timeshift\n",
    "\n",
    "n_processes = 21\n",
    "  \n",
    "def fun(s,rfa,dropcountries):\n",
    "\n",
    "    p = rfa.get_optimal_parameters(\"R2_test\",s)\n",
    "    d = p[1]\n",
    "    m = p[2]\n",
    "    \n",
    "    return rfa.get_permutation_importance(time_shift=s,min_samples_leaf=1,max_depth=d,max_features=m,n_splits=10,n_repeats=200,drop_countries=dropcountries)\n",
    "\n",
    "for continent in ['None','Europe','Asia','Americas']:\n",
    "\n",
    "    args = list(map(lambda s: (s,rfa,countrylists[continent]),t))\n",
    "\n",
    "    pool = mp.Pool(processes=n_processes)\n",
    "\n",
    "    newres = pool.starmap(fun,args)\n",
    "\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    permutation_importances[continent] = pd.concat(newres)\n",
    "\n",
    "    rfa.permutation_importances = permutation_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtain feature ranking for main analysis and different knockout experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dropped_continent = 'None' # change to 'Europe','Asia' or 'Americas'\n",
    "\n",
    "RFA.feature_ranking(rfa.permutation_importances[dropped_continent])[['Measure','mean_Delta',\"CI\"]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
